{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA-Topic Modelling / Theme extraction - .ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1E1xZpuvsHvbwXNTXvWScWovodp0PJQSt",
      "authorship_tag": "ABX9TyM0PGmxpgWa7pF6G8iVf/Jb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvaravii/BBC-News-article-Topic-Identification/blob/main/LDA_Topic_Modelling_Theme_extraction_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem Description**\n",
        "\n",
        "In this project your task is to identify major themes/topics across a collection of BBC news articles. You can use clustering algorithms such as Latent Dirichlet Allocation (LDA), Latent Semantic Analysis (LSA) etc."
      ],
      "metadata": {
        "id": "IMhNtuuHfOm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for dataframes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "#for ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "\n",
        "\n",
        "#gensim\n",
        "import gensim\n",
        "import gensim.corpora as corpora \n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "\n",
        "from spacy import displacy\n",
        "from gensim.corpora import Dictionary\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "import sklearn\n",
        "import keras\n",
        "\n",
        "#spacy\n",
        "import spacy \n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# for visualisation of data\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "e_WmS-QpfPN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processed_data_filepath='/content/drive/MyDrive/Colab Notebooks/Capstone Project/BBC article/2. Cleaned and Preprocessed data/3rd_cleaned_dataset_stg.csv'\n",
        "new_df=pd.read_csv(processed_data_filepath)\n",
        "df=new_df.copy()\n",
        "df=df.drop(columns={'Unnamed: 0'})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "8HCWPi34fnZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## building LDA MODEL"
      ],
      "metadata": {
        "id": "uOwIqP-jfcM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While using the gensim for topic modelling it does not need DTM(Document term matrix) as it has its internal mechanism to create DTM."
      ],
      "metadata": {
        "id": "9n4do70CJG5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus=df['cleaned_doc_token'].apply(eval)\n",
        "corpus = [d for d in corpus]\n",
        "dict_=corpora.Dictionary(corpus)\n",
        "print(dict_)"
      ],
      "metadata": {
        "id": "KFhDn9iafbia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dict_.values():\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "dvsMqU-Qgqd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the dict into Document term matrix\n",
        "doc_term_matrix = [dict_.doc2bow(i) for i in corpus]\n",
        "\n",
        "# def doc2bow(document, allow_update=False, return_missing=False)\n",
        "# Convert document into the bag-of-words (BoW) format = list of (token_id, token_count) tuples.\n",
        "\n",
        "doc_term_matrix # Bag of words looks like"
      ],
      "metadata": {
        "id": "UChS_1X4PJTU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we obtained the bag of words we implement lda\n",
        "\n",
        "########################### BLOCK -1 LDA IMPLEMENTATION #######################\n",
        "\n",
        "# Creating object for gensim library for lda model\n",
        "\n",
        "lda = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Training and running the LDA model.\n",
        "lda_model = lda(doc_term_matrix,num_topics=10,id2word=dict_, passes=10,random_state=100,eval_every=None)"
      ],
      "metadata": {
        "id": "KVu7vkSKQxDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # most frequent words #said,one,would,could,Mr,Ms,also,last,first,year,told,new,ask,two,like,many,take,years,people\n",
        " lda_model.print_topics()"
      ],
      "metadata": {
        "id": "FQI50oyRRiN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, doc_term_matrix, dict_)\n",
        "vis\n"
      ],
      "metadata": {
        "id": "2pxLd868SXL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords  #stopwords\n",
        "from nltk.stem import WordNetLemmatizer  \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "stop_words=set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000)\n",
        "vect_text=vect.fit_transform(df['cleaned_doc'])\n",
        "\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model=LatentDirichletAllocation(n_components=10,learning_method='online',random_state=42,max_iter=10) \n",
        "lda_top=lda_model.fit_transform(vect_text)\n",
        "\n",
        "vocab = vect.get_feature_names()\n",
        "for i, comp in enumerate(lda_model.components_):\n",
        "     vocab_comp = zip(vocab, comp)\n",
        "     sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
        "     \n",
        "     print(\"Topic \"+str(i)+\": \")\n",
        "     for t in sorted_words:\n",
        "            print(t[0],end=\" \")\n",
        "     print(\"\\n\")\n",
        "     "
      ],
      "metadata": {
        "id": "HEoeVV7zvGw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set 2"
      ],
      "metadata": {
        "id": "oaZu5PakpVbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we obtained the bag of words we implement lda\n",
        "\n",
        "########################### BLOCK -1 LDA IMPLEMENTATION #######################\n",
        "\n",
        "# Creating object for gensim library for lda model\n",
        "\n",
        "lda = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Training and running the LDA model.\n",
        "lda_model = lda(doc_term_matrix,num_topics=3,id2word=dict_, passes=10,chunksize=400,random_state=100,eval_every=None)\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, doc_term_matrix, dict_)\n",
        "vis"
      ],
      "metadata": {
        "id": "x6_jsw3fpUYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set 3"
      ],
      "metadata": {
        "id": "uek5qLdEpdaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Since we obtained the bag of words we implement lda\n",
        "\n",
        "########################### BLOCK -1 LDA IMPLEMENTATION #######################\n",
        "\n",
        "# Creating object for gensim library for lda model\n",
        "\n",
        "lda = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Training and running the LDA model.\n",
        "lda_model = lda(doc_term_matrix,num_topics=5,id2word=dict_, passes=10,chunksize=400,random_state=100,eval_every=None)\n",
        "\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model,doc_term_matrix, dict_)\n",
        "vis"
      ],
      "metadata": {
        "id": "484XHtnhmnfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation metric"
      ],
      "metadata": {
        "id": "H7KL-IIoptqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus, dictionary=dict_, coherence='c_v',)\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "metadata": {
        "id": "dKoY48K7pkQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyper parameter tuning using the coherence score\n",
        "\n",
        "lda = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# hyperparamters = num_topics\n",
        "\n",
        "num_topics=list(range(3,15))\n",
        "dict_hyp={}\n",
        "for i in num_topics:\n",
        "  # Training and running the LDA model.\n",
        "  lda_model = lda(doc_term_matrix,num_topics=i,id2word=dict_, passes=5,chunksize=40,eval_every=None)\n",
        "\n",
        "  coherence_model_lda = CoherenceModel(model=lda_model, texts=corpus, dictionary=dict_, coherence='c_v',)\n",
        "  coherence_lda = coherence_model_lda.get_coherence()\n",
        "  dict_hyp[i]=coherence_lda\n",
        "  print('\\nCoherence Score when num_of_topic is : '+str(i)+'  -------->',coherence_lda)"
      ],
      "metadata": {
        "id": "a9-K9ye3KiaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "D = dict_hyp\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "ax=plt.barh(range(len(D))[::-1], D.values(), align='center')\n",
        "plt.yticks(range(len(D))[::-1], list(D.keys()))\n",
        "plt.ylabel('Number of topics')\n",
        "plt.xlabel('Coherence Score')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qSziHuFiH2CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################## TUNING OF ALPHA *****************************************\n"
      ],
      "metadata": {
        "id": "IWU_0iKCQpq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose αm from [0.05,0.1,0.5,1,5,10]\n",
        "Choose βm from [0.05,0.1,0.5,1,5,10]"
      ],
      "metadata": {
        "id": "A_UxtMQFxZHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5vog4Q_iQPow"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}